{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-science-bowl-2019/sample_submission.csv\n",
      "/kaggle/input/data-science-bowl-2019/specs.csv\n",
      "/kaggle/input/data-science-bowl-2019/train_labels.csv\n",
      "/kaggle/input/data-science-bowl-2019/train.csv\n",
      "/kaggle/input/data-science-bowl-2019/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import gc\n",
    "import json\n",
    "pd.set_option('display.max_columns', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "* In the last notebook we create our baseline model including a feature selection part. \n",
    "* Cohen cappa score of 0.456 (lb) with a local cv score of 0.529\n",
    "* In this notebook we are going to add more features and remove others that i think they overfitt the train set and then check if our local cv score improve.\n",
    "* Next, we will check if this improvement aligns with the lb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Check the distribution of the target variable of the out of folds score and the prediction distribution. A good model should more or less have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function that convert the raw data into processed features\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    \n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    event_code_count = {eve: 0 for eve in list_of_event_code}\n",
    "    last_session_time_sec = 0\n",
    "    \n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    \n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "                    \n",
    "            \n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(event_code_count.copy())\n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "                \n",
    "            counter += 1\n",
    "        \n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        n_of_event_codes = Counter(session['event_code'])\n",
    "        \n",
    "        for key in n_of_event_codes.keys():\n",
    "            event_code_count[key] += n_of_event_codes[key]\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_feature_selection(reduce_train, reduce_test, usefull_features, new_features):\n",
    "    kf = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\n",
    "    target = 'accuracy_group'\n",
    "    oof_pred = np.zeros((len(reduce_train), 4))\n",
    "    for fold, (tr_ind, val_ind) in enumerate(kf.split(reduce_train, reduce_train[target])):\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "        x_train, x_val = reduce_train[usefull_features].iloc[tr_ind], reduce_train[usefull_features].iloc[val_ind]\n",
    "        y_train, y_val = reduce_train[target][tr_ind], reduce_train[target][val_ind]\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature = categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature = categoricals)\n",
    "\n",
    "        params = {\n",
    "            'learning_rate': 0.01,\n",
    "            'metric': 'multiclass',\n",
    "            'objective': 'multiclass',\n",
    "            'num_classes': 4,\n",
    "            'feature_fraction': 0.75,\n",
    "            'subsample': 0.75,\n",
    "            'n_jobs': -1,\n",
    "            'seed': 50,\n",
    "            'max_depth': 10\n",
    "        }\n",
    "\n",
    "        model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 100, \n",
    "                          valid_sets=[train_set, val_set], verbose_eval = 500)\n",
    "        oof_pred[val_ind] = model.predict(x_val)\n",
    "    # using cohen_kappa because it's the evaluation metric of the competition\n",
    "    loss_score = cohen_kappa_score(reduce_train[target], np.argmax(oof_pred, axis = 1), weights = 'quadratic')\n",
    "    score = loss_score\n",
    "    usefull_new_features = []\n",
    "    for i in new_features:\n",
    "        oof_pred = np.zeros((len(reduce_train), 4))\n",
    "        evaluating_features = usefull_features + usefull_new_features + [i]\n",
    "        print('Evaluating {} column'.format(i))\n",
    "        print('Out best cohen kappa score is : {}'.format(score))\n",
    "        for fold, (tr_ind, val_ind) in enumerate(kf.split(reduce_train, reduce_train[target])):\n",
    "            print('Fold {}'.format(fold + 1))\n",
    "            x_train, x_val = reduce_train[evaluating_features].iloc[tr_ind], reduce_train[evaluating_features].iloc[val_ind]\n",
    "            y_train, y_val = reduce_train[target][tr_ind], reduce_train[target][val_ind]\n",
    "            train_set = lgb.Dataset(x_train, y_train, categorical_feature = categoricals)\n",
    "            val_set = lgb.Dataset(x_val, y_val, categorical_feature = categoricals)\n",
    "\n",
    "            model = lgb.train(params, train_set, num_boost_round = 100000, early_stopping_rounds = 100, \n",
    "                              valid_sets=[train_set, val_set], verbose_eval = 500)\n",
    "            oof_pred[val_ind] = model.predict(x_val)\n",
    "        loss_score = cohen_kappa_score(reduce_train[target], np.argmax(oof_pred, axis = 1), weights = 'quadratic')\n",
    "        print('Our new cohen kappa score is : {}'.format(loss_score))\n",
    "        if loss_score > score:\n",
    "            print('Feature {} is usefull, adding feature to usefull_new_features_list'.format(i))\n",
    "            usefull_new_features.append(i)\n",
    "            score = loss_score\n",
    "        else:\n",
    "            print('Feature {} is useless'.format(i))\n",
    "        gc.collect()\n",
    "    print('The best features are: ', usefull_new_features)\n",
    "    print('Our best cohen kappa score is : ', score)\n",
    "\n",
    "    return usefull_features + usefull_new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lgb(reduce_train, reduce_test, usefull_features):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle = True, random_state = 42)\n",
    "    target = 'accuracy_group'\n",
    "    oof_pred = np.zeros((len(reduce_train), 4))\n",
    "    y_pred = np.zeros((len(reduce_test), 4))\n",
    "    for fold, (tr_ind, val_ind) in enumerate(kf.split(reduce_train, reduce_train[target])):\n",
    "        print('Fold {}'.format(fold + 1))\n",
    "        x_train, x_val = reduce_train[usefull_features].iloc[tr_ind], reduce_train[usefull_features].iloc[val_ind]\n",
    "        y_train, y_val = reduce_train[target][tr_ind], reduce_train[target][val_ind]\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=categoricals)\n",
    "\n",
    "        params = {\n",
    "            'learning_rate': 0.01,\n",
    "            'metric': 'multiclass',\n",
    "            'objective': 'multiclass',\n",
    "            'num_classes': 4,\n",
    "            'feature_fraction': 0.75,\n",
    "            'subsample': 0.75,\n",
    "            'n_jobs': -1,\n",
    "            'seed': 50,\n",
    "            'max_depth': 10\n",
    "        }\n",
    "\n",
    "        model = lgb.train(params, train_set, num_boost_round = 1000000, early_stopping_rounds = 50, \n",
    "                          valid_sets=[train_set, val_set], verbose_eval = 100)\n",
    "        oof_pred[val_ind] = model.predict(x_val)\n",
    "        y_pred += model.predict(reduce_test[usefull_features]) / 5\n",
    "    loss_score = cohen_kappa_score(reduce_train[target], np.argmax(oof_pred, axis = 1), weights = 'quadratic')\n",
    "    result = pd.Series(np.argmax(oof_pred, axis = 1))\n",
    "    print('Our oof cohen kappa score is: ', loss_score)\n",
    "    print(result.value_counts(normalize = True))\n",
    "    return y_pred\n",
    "\n",
    "def predict(reduce_test, sample_submission, y_pred):\n",
    "    sample_submission['accuracy_group'] = y_pred.argmax(axis = 1)\n",
    "    sample_submission.to_csv('submission.csv', index = False)\n",
    "    print(sample_submission['accuracy_group'].value_counts(normalize = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv file....\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd2287c816341c8812d0c3e7968c7fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab923ad9e1f49e18a3a4c0a16cdeb4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that creates more features\n",
    "def preprocess(reduce_train, reduce_test):\n",
    "    for df in [reduce_train, reduce_test]:\n",
    "        df['installation_session_count'] = df.groupby(['installation_id'])['Clip'].transform('count')\n",
    "        df['installation_duration_mean'] = df.groupby(['installation_id'])['duration_mean'].transform('mean')\n",
    "        #df['installation_duration_std'] = df.groupby(['installation_id'])['duration_mean'].transform('std')\n",
    "        df['installation_title_nunique'] = df.groupby(['installation_id'])['session_title'].transform('nunique')\n",
    "        \n",
    "        df['sum_event_code_count'] = df[[2050, 4100, 4230, 5000, 4235, 2060, 4110, 5010, 2070, 2075, 2080, 2081, 2083, 3110, 4010, 3120, 3121, 4020, 4021, \n",
    "                                        4022, 4025, 4030, 4031, 3010, 4035, 4040, 3020, 3021, 4045, 2000, 4050, 2010, 2020, 4070, 2025, 2030, 4080, 2035, \n",
    "                                        2040, 4090, 4220, 4095]].sum(axis = 1)\n",
    "        \n",
    "        df['installation_event_code_count_mean'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('mean')\n",
    "        #df['installation_event_code_count_std'] = df.groupby(['installation_id'])['sum_event_code_count'].transform('std')\n",
    "        \n",
    "    features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "    features = [x for x in features if x not in ['accuracy_group', 'installation_id']]\n",
    "    return reduce_train, reduce_test, features\n",
    "# call feature engineering function\n",
    "reduce_train, reduce_test, features = preprocess(reduce_train, reduce_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # next codes are to select only the feature that increase our cohen kappe score\n",
    "# new_features = ['installation_session_count', 'installation_duration_mean', 'installation_duration_std', 'installation_title_nunique', 'sum_event_code_count', 'installation_event_code_count_mean', \n",
    "#                 'installation_event_code_count_std']\n",
    "# usefull_features = [col for col in features if col not in new_features]\n",
    "# best_features = run_feature_selection(reduce_train, reduce_test, usefull_features, new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 1.04385\tvalid_1's multi_logloss: 1.08055\n",
      "[200]\ttraining's multi_logloss: 0.964408\tvalid_1's multi_logloss: 1.02936\n",
      "[300]\ttraining's multi_logloss: 0.914758\tvalid_1's multi_logloss: 1.0077\n",
      "[400]\ttraining's multi_logloss: 0.876936\tvalid_1's multi_logloss: 0.996645\n",
      "[500]\ttraining's multi_logloss: 0.845195\tvalid_1's multi_logloss: 0.989933\n",
      "[600]\ttraining's multi_logloss: 0.817645\tvalid_1's multi_logloss: 0.986487\n",
      "[700]\ttraining's multi_logloss: 0.793424\tvalid_1's multi_logloss: 0.984265\n",
      "[800]\ttraining's multi_logloss: 0.770923\tvalid_1's multi_logloss: 0.982712\n",
      "[900]\ttraining's multi_logloss: 0.749483\tvalid_1's multi_logloss: 0.981438\n",
      "[1000]\ttraining's multi_logloss: 0.729089\tvalid_1's multi_logloss: 0.980924\n",
      "[1100]\ttraining's multi_logloss: 0.709784\tvalid_1's multi_logloss: 0.980783\n",
      "Early stopping, best iteration is:\n",
      "[1062]\ttraining's multi_logloss: 0.717036\tvalid_1's multi_logloss: 0.980668\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 1.04344\tvalid_1's multi_logloss: 1.07718\n",
      "[200]\ttraining's multi_logloss: 0.963166\tvalid_1's multi_logloss: 1.0268\n",
      "[300]\ttraining's multi_logloss: 0.913005\tvalid_1's multi_logloss: 1.00656\n",
      "[400]\ttraining's multi_logloss: 0.874831\tvalid_1's multi_logloss: 0.996164\n",
      "[500]\ttraining's multi_logloss: 0.842976\tvalid_1's multi_logloss: 0.990244\n",
      "[600]\ttraining's multi_logloss: 0.814924\tvalid_1's multi_logloss: 0.986617\n",
      "[700]\ttraining's multi_logloss: 0.790309\tvalid_1's multi_logloss: 0.983926\n",
      "[800]\ttraining's multi_logloss: 0.768027\tvalid_1's multi_logloss: 0.982742\n",
      "[900]\ttraining's multi_logloss: 0.746928\tvalid_1's multi_logloss: 0.982466\n",
      "Early stopping, best iteration is:\n",
      "[913]\ttraining's multi_logloss: 0.744271\tvalid_1's multi_logloss: 0.982428\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 1.04298\tvalid_1's multi_logloss: 1.07961\n",
      "[200]\ttraining's multi_logloss: 0.962237\tvalid_1's multi_logloss: 1.03084\n",
      "[300]\ttraining's multi_logloss: 0.912065\tvalid_1's multi_logloss: 1.01097\n",
      "[400]\ttraining's multi_logloss: 0.873865\tvalid_1's multi_logloss: 1.00006\n",
      "[500]\ttraining's multi_logloss: 0.842409\tvalid_1's multi_logloss: 0.993746\n",
      "[600]\ttraining's multi_logloss: 0.81492\tvalid_1's multi_logloss: 0.98972\n",
      "[700]\ttraining's multi_logloss: 0.790032\tvalid_1's multi_logloss: 0.9872\n",
      "[800]\ttraining's multi_logloss: 0.767498\tvalid_1's multi_logloss: 0.985603\n",
      "[900]\ttraining's multi_logloss: 0.746188\tvalid_1's multi_logloss: 0.984167\n",
      "[1000]\ttraining's multi_logloss: 0.725924\tvalid_1's multi_logloss: 0.983386\n",
      "[1100]\ttraining's multi_logloss: 0.706925\tvalid_1's multi_logloss: 0.982668\n",
      "Early stopping, best iteration is:\n",
      "[1126]\ttraining's multi_logloss: 0.70216\tvalid_1's multi_logloss: 0.982444\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 1.04266\tvalid_1's multi_logloss: 1.08076\n",
      "[200]\ttraining's multi_logloss: 0.961467\tvalid_1's multi_logloss: 1.03212\n",
      "[300]\ttraining's multi_logloss: 0.911137\tvalid_1's multi_logloss: 1.01234\n",
      "[400]\ttraining's multi_logloss: 0.872992\tvalid_1's multi_logloss: 1.00238\n",
      "[500]\ttraining's multi_logloss: 0.841515\tvalid_1's multi_logloss: 0.996325\n",
      "[600]\ttraining's multi_logloss: 0.814756\tvalid_1's multi_logloss: 0.992502\n",
      "[700]\ttraining's multi_logloss: 0.79068\tvalid_1's multi_logloss: 0.99047\n",
      "[800]\ttraining's multi_logloss: 0.768107\tvalid_1's multi_logloss: 0.989457\n",
      "[900]\ttraining's multi_logloss: 0.747049\tvalid_1's multi_logloss: 0.988643\n",
      "[1000]\ttraining's multi_logloss: 0.727013\tvalid_1's multi_logloss: 0.988107\n",
      "Early stopping, best iteration is:\n",
      "[1015]\ttraining's multi_logloss: 0.724085\tvalid_1's multi_logloss: 0.988084\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's multi_logloss: 1.04483\tvalid_1's multi_logloss: 1.0753\n",
      "[200]\ttraining's multi_logloss: 0.964595\tvalid_1's multi_logloss: 1.02369\n",
      "[300]\ttraining's multi_logloss: 0.915246\tvalid_1's multi_logloss: 1.00212\n",
      "[400]\ttraining's multi_logloss: 0.877745\tvalid_1's multi_logloss: 0.992202\n",
      "[500]\ttraining's multi_logloss: 0.846566\tvalid_1's multi_logloss: 0.986336\n",
      "[600]\ttraining's multi_logloss: 0.819101\tvalid_1's multi_logloss: 0.98263\n",
      "[700]\ttraining's multi_logloss: 0.794686\tvalid_1's multi_logloss: 0.980589\n",
      "[800]\ttraining's multi_logloss: 0.771945\tvalid_1's multi_logloss: 0.979691\n",
      "[900]\ttraining's multi_logloss: 0.749952\tvalid_1's multi_logloss: 0.978874\n",
      "[1000]\ttraining's multi_logloss: 0.729514\tvalid_1's multi_logloss: 0.978058\n",
      "Early stopping, best iteration is:\n",
      "[1031]\ttraining's multi_logloss: 0.723265\tvalid_1's multi_logloss: 0.977908\n",
      "Our oof cohen kappa score is:  0.5289157956304292\n",
      "3    0.691464\n",
      "0    0.239401\n",
      "1    0.062804\n",
      "2    0.006331\n",
      "dtype: float64\n",
      "3    0.712\n",
      "0    0.234\n",
      "1    0.052\n",
      "2    0.002\n",
      "Name: accuracy_group, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_pred = run_lgb(reduce_train, reduce_test, features)\n",
    "predict(reduce_test, sample_submission, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f12c53e6636489598aeb773d7386a6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1132172483d24109887c3f98e4e1e9e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1454053418724b5db36bafa9c028f519",
       "placeholder": "​",
       "style": "IPY_MODEL_5a1ec01b544c46d89c42990e71aa0c7f",
       "value": " 1000/1000 [03:08&lt;00:00,  5.31it/s]"
      }
     },
     "1454053418724b5db36bafa9c028f519": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15b9751257b542188dd44f1f432f2fca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d14690dfde0240949bc8571518801f92",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6f3bdacf15c042e2923f00f897ba1e40",
       "value": 1000
      }
     },
     "5432f839d6ca4b13b0e00d7cfa57d499": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd2f6ae7bfdd42e8a8a55b30de7cef65",
       "placeholder": "​",
       "style": "IPY_MODEL_0f12c53e6636489598aeb773d7386a6e",
       "value": " 17000/17000 [08:52&lt;00:00, 31.92it/s]"
      }
     },
     "5a1ec01b544c46d89c42990e71aa0c7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "631a849b25134316ad3c210c78d8f262": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6f3bdacf15c042e2923f00f897ba1e40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "8a079f903ebc4a46b48f3d14857e3fe8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a0d46f2f712a44a2912f425a5d81885d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a7b8abe4bd5b4469a154ef200cd439c0",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8a079f903ebc4a46b48f3d14857e3fe8",
       "value": 17000
      }
     },
     "a7b8abe4bd5b4469a154ef200cd439c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdd2287c816341c8812d0c3e7968c7fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a0d46f2f712a44a2912f425a5d81885d",
        "IPY_MODEL_5432f839d6ca4b13b0e00d7cfa57d499"
       ],
       "layout": "IPY_MODEL_631a849b25134316ad3c210c78d8f262"
      }
     },
     "d14690dfde0240949bc8571518801f92": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd2f6ae7bfdd42e8a8a55b30de7cef65": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec4a08827d4f4d34a531622fcb82a985": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fab923ad9e1f49e18a3a4c0a16cdeb4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_15b9751257b542188dd44f1f432f2fca",
        "IPY_MODEL_1132172483d24109887c3f98e4e1e9e7"
       ],
       "layout": "IPY_MODEL_ec4a08827d4f4d34a531622fcb82a985"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
