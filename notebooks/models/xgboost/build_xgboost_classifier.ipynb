{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST - TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = 'data/processed/'\n",
    "SEED = 47\n",
    "NITER = 100\n",
    "CV = 5\n",
    "SCORE = 'roc_auc'\n",
    "handlingnull = False\n",
    "NJOBS = -1\n",
    "USEGPU = False\n",
    "NCLASS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_pickle(DATAPATH+'X.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212665, 1205)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_pickle(DATAPATH+'y.pkl')[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = pd.read_pickle('data/features/campaign_quarter_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "digital = pd.read_pickle('data/features/digital_features_period_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc = pd.read_pickle('data/features/X_rcc_features_ten_001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcc.drop(['id_persona', 'codmes'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.join(campaign).join(rcc).join(digital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(212665, 1770)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_features = train_features.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create a DMatrix and handling Null values\n",
    "if handlingnull:\n",
    "    #train_features[np.isnan(train_features)] = -9999\n",
    "    xgtrain = xgb.DMatrix(train_features.values, train_labels.values, missing=-9999)\n",
    "else:\n",
    "    xgtrain = xgb.DMatrix(train_features.values, train_labels.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== General Parameters ======= #\n",
    "\n",
    "# Select the type of model to run at each iteration. gbtree or gblinear.\n",
    "booster = 'gbtree'\n",
    "\n",
    "\n",
    "# ======== Booster Parameters ======== # \n",
    "\n",
    "# Analogous to learning rate in GBM. \n",
    "# Typical final values to be used: 0.01-0.2\n",
    "eta = [0.01] \n",
    "\n",
    "\n",
    "# Control the balance of positive and negative weights, useful for unbalanced classes. \n",
    "# A typical value to consider: sum(negative instances) / sum(positive instances)scale_pos_weight = 1\n",
    "scale_pos_weight = int((len(train_labels) - np.sum(train_labels.values))/np.sum(train_labels.values))\n",
    "\n",
    "\n",
    "# Learning Task Parameters\n",
    "\n",
    "# This defines the loss function to be minimized. \n",
    "# - binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "# - multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "#   you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "# - multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "objective  = 'binary:logistic'\n",
    "\n",
    "\n",
    "# The metric to be used for validation data.\n",
    "# - rmse – root mean square error\n",
    "# - mae – mean absolute error\n",
    "# - logloss – negative log-likelihood\n",
    "# - error – Binary classification error rate (0.5 threshold)\n",
    "# - merror – Multiclass classification error rate\n",
    "# - mlogloss – Multiclass logloss\n",
    "# - auc: Area under the curve\n",
    "eval_metric = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param = np.load('output/hyperparameters/rseach_xgboost_classifier_bestparams_d2019-11-20.npy').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.6,\n",
       " 'reg_lambda': 0.9,\n",
       " 'reg_alpha': 0.01,\n",
       " 'min_child_weight': 9,\n",
       " 'max_depth': 9,\n",
       " 'learning_rate': 0.01,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.6}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_param['seed'] = SEED\n",
    "model_param['booster'] = booster\n",
    "model_param['objective'] = objective\n",
    "model_param['n_estimator'] = 313\n",
    "model_param['scale_pos_weight'] = scale_pos_weight\n",
    "model_param['nthread'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:11:00] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 712 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:01] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 664 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:03] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 742 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:05] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 740 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:07] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 738 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:09] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 774 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:11] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 610 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:13] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 764 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:14] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 732 extra nodes, 0 pruned nodes, max_depth=9\n",
      "[02:11:16] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 712 extra nodes, 0 pruned nodes, max_depth=9\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(model_param, xgtrain, verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(xgtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc  :  0.8206426125225773\n"
     ]
    }
   ],
   "source": [
    "print(SCORE,' : ', roc_auc_score(train_labels.values,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('models/xgb_002.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('models/xgb_002.features', train_features.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xgboost (env)",
   "language": "python",
   "name": "xgboostenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
